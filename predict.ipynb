{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Load libs"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import random\nfrom datetime import datetime\n\nimport os\nimport numpy as np\nimport pandas as pd \nfrom skimage.io import imread\nfrom skimage.morphology import label\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm_notebook\nfrom skimage.morphology import binary_opening, disk\n\nfrom keras.utils import Sequence\nfrom keras.models import load_model","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nprint(\"keras:\", keras.__version__)\n\nimport skimage \nprint(\"skimage:\", skimage.__version__)\n\nimport matplotlib\nprint(\"matplotlib:\", matplotlib.__version__)\n\nimport tqdm\nprint(\"tqdm:\", tqdm.__version__)\n\nimport numpy\nprint(\"numpy:\", numpy.__version__)\n\nimport pandas\nprint(\"pandas:\", pandas.__version__)\n","execution_count":6,"outputs":[{"output_type":"stream","text":"keras: 2.2.4\nskimage: 0.13.0\nmatplotlib: 2.2.3\ntqdm: 4.26.0\nnumpy: 1.15.2\npandas: 0.23.4\n","name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"module 'datetime' has no attribute '__version__'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-5d1f0ccbd898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datetime:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'datetime' has no attribute '__version__'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"PRETRAINED_DETECTOR_PATH = '../input/airbus-ship-detection-resnet34-256px/ResNet34_ship_detection_256_4.h5'\nPRETRAINED_SEG_MODEL_PATH = '../input/airbus-seg-model-768-sr-0741/seg_model_768_ships_ratio_0741_5hr.h5'\n\nSHIP_DET_DF = '../input/airbus-has-ship-or-not/has_ship_or_not.csv'\n\nSHIP_DIR = '../input/airbus-ship-detection'\nTRAIN_IMAGE_DIR = os.path.join(SHIP_DIR, 'train_v2')\nTEST_IMAGE_DIR = os.path.join(SHIP_DIR, 'test_v2')\n\nMASKS_DF_PATH = 'train_ship_segmentations_v2.csv'  # for vis. train GT","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict ship detection on images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def multi_rle_encode(img):\n    labels = label(img[:, :, 0])\n    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction\n\ndef masks_as_image(in_mask_list):\n    # Take the individual ship masks and create a single mask array for all ships\n    all_masks = np.zeros((768, 768), dtype = np.int16)\n    #if isinstance(in_mask_list, list):\n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            all_masks += rle_decode(mask)\n    return np.expand_dims(all_masks, -1)\n\n\nclass DataGenerator(Sequence):\n    'Generates data for Keras'\n    def __init__(self, test_names, batch_size=32, resize_to=None):\n        'Initialization'\n        self.test_names = test_names\n        self.batch_size = batch_size\n        self.resize_to = resize_to\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.test_names) / self.batch_size))\n \n    def __data_generation(self, test_names_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, self.resize_to, self.resize_to, 3), dtype='float32')\n#         y = np.empty((self.batch_size, self.resize_to, self.resize_to, 1), dtype='uint8')\n        \n        # Generate data\n        for i, img_name in enumerate(test_names_temp):\n            rgb_path = os.path.join(TEST_IMAGE_DIR, img_name)\n            img = Image.open(rgb_path).convert('RGB')\n            if self.resize_to is not None:\n                img = img.resize((self.resize_to,self.resize_to))\n            img = np.array(img)/255.0\n                \n            # Store sample\n            X[i,] = img\n            # Store class\n#             y[i] = c_mask\n        return X#, y\n    \n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        test_names_temp = self.test_names[index*self.batch_size:(index+1)*self.batch_size]\n        # Generate data\n        X = self.__data_generation(test_names_temp)  # ~1.5s\n        return X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Main function"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ShipSegmentator(object):\n    \"\"\"\n    Class is responsible for test data ship segmentation having trained segmentation model\n        and detection dataframe (has_ship=1/2 for every test image) or trained detector\n    \"\"\"\n    def __init__(self, pretrained_seg_path, ship_dir=SHIP_DIR, pretrained_det_path=None, ship_det_df_path=SHIP_DET_DF, masks_df_path=MASKS_DF_PATH):\n        \"\"\"\n        @pretrained_seg_path (str): path to pretrained segmentation model\n        @ship_images_dir (str): path to folder that has subfolder 'test_v2' with test images\n        @pretrained_det_path (str): path to pretrained deteciton model path (model predicts the probability of a ship in the image)\n        @ship_det_df_path (str): SHIP_DET_DF): path to csv with df: columns=[ImageId, has_ship(0/1)]\n        \"\"\"\n        self.train_image_dir = os.path.join(ship_dir, 'train_v2')\n        self.test_image_dir = os.path.join(ship_dir, 'test_v2')\n        self.test_names = os.listdir(self.test_image_dir)\n        self.ship_det_df_path = ship_det_df_path\n        self.pretrained_det_path = pretrained_det_path\n        self.masks = pd.read_csv(os.path.join(ship_dir, masks_df_path))\n        \n        self.seg_model = load_model(pretrained_seg_path, compile=False)\n        print(\"Segmentation model loaded!\")\n\n        self._split_ship_no_ship_images()\n    \n    def _split_ship_no_ship_images(self):\n        if self.ship_det_df_path is None:\n            print(\"File has_ship_or_not csv doesn't exist. \\nPredict them using detector ->\")\n            det_df = self.predict_ship_exist_in_image(self.pretrained_det_path)\n        else:\n            print(\"Opening has_ship_or_not csv file...\")\n            det_df = pd.read_csv(self.ship_det_df_path)\n            \n        self.test_names_ship = det_df.loc[det_df['has_ship'] >= 0.5, ['ImageId']]['ImageId'].values.tolist()\n        self.test_names_nothing = det_df.loc[det_df['has_ship'] < 0.5, ['ImageId']]['ImageId'].values.tolist()\n        print(\"'Ship' images:{}, 'no ship' images:{}\".format(len(self.test_names_ship), len(self.test_names_nothing)))\n            \n        \n    def predict_ship_exist_in_image(self, pretrained_det_path):\n        det_model = load_model(pretrained_det_path, compile=False)\n        test_generator = DataGenerator(self.test_names, batch_size=54, resize_to=256)  # 15606/54 = int, so last batch included\n        print(\"Ship on images prediction takes about 5 mins...\")\n        result = det_model.predict_generator(test_generator)[:, 0]\n        result = (result >= 0.5).astype(int)\n        ship_det_df = pd.DataFrame({\n            \"ImageId\": test_names,\n            \"has_ship\":result\n        })\n        ship_det_df.to_csv('has_ship_or_not.csv',index = False)\n        return ship_det_df\n\n    def visualize_ship_segmentation(self, n_images=10, is_train=False, shuffle=False):\n        if is_train:\n            # pick only ship exist images\n            img_names_list = self.masks[~self.masks['EncodedPixels'].isna()]['ImageId'].unique()\n            n_columns = 3\n            images_dir = self.train_image_dir\n        else:\n            img_names_list = self.test_names_ship\n            n_columns = 2\n            images_dir = self.test_image_dir\n        if shuffle:\n            random.shuffle(img_names_list)\n        \n        fig, m_axs = plt.subplots(n_images, n_columns, figsize = (5*n_columns, 4*n_images))\n        for axes, img_name in zip(m_axs, img_names_list):\n            path = os.path.join(images_dir, img_name)\n            img = imread(path)\n            img = np.expand_dims(img, 0)/255.0\n            seg_mask = self.seg_model.predict(img)\n\n            \n            axes[0].imshow(img[0])\n            axes[0].set_title(img_name)\n            axes[1].imshow(seg_mask[0, :, :, 0], vmin = 0, vmax = 1)\n            axes[1].set_title('Prediction')\n            if is_train:\n                true_mask = masks_as_image(self.masks[self.masks['ImageId']==img_name]['EncodedPixels'].values)\n                axes[2].imshow(true_mask[:,:,0], cmap='gray')\n                axes[2].set_title('Ground Truth')\n        plt.show()\n#         fig.savefig('test_predictions.png')\n\n    def predict_ship_masks_to_csv(self):\n        \"\"\"\n        Main function that predict mask for images\n        classified as 'has ship' by the classifier. \n        Encode RLEs to submission file if mask predicted,\n        if model predicts empty mask that also put NaN to 'EncodedPixels' columns\n        as for 'no ship' images from classifier(detector)\n        \"\"\"\n        # put 'no ship' images to final sub dict\n        ship_list_dict = []\n        for name in test_names_nothing:\n            ship_list_dict.append({'ImageId':name,'EncodedPixels':None})\n              \n        print(\"Start segmentation prediction:\", datetime.now())\n        for img_name in tqdm_notebook(test_names_ship):\n            if img_name in test_names:\n                path = os.path.join(TEST_IMAGE_DIR, img_name)\n                img = imread(path)\n                img = np.expand_dims(img, 0)/255.0\n                cur_seg = self.seg_model.predict(img)[0]\n                cur_seg = binary_opening(cur_seg>=0.5, np.expand_dims(disk(2), -1))\n                cur_rles = multi_rle_encode(cur_seg)\n                if len(cur_rles)>0:\n                    for c_rle in cur_rles:\n                        ship_list_dict += [{'ImageId': img_name, 'EncodedPixels': c_rle}]\n                else:\n                    ship_list_dict += [{'ImageId': img_name, 'EncodedPixels': None}]\n            else:\n                print(\"img_name is not in self.test_names. img_name:\", img_name)\n            gc.collect()\n              \n        submission_df = pd.DataFrame(ship_list_dict)[['ImageId', 'EncodedPixels']]\n        submission_df.to_csv('submission.csv', index=False)\n        return submission_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ship_segmentator = ShipSegmentator(pretrained_seg_path=PRETRAINED_SEG_MODEL_PATH, ship_dir=SHIP_DIR, pretrained_det_path=None, ship_det_df_path=SHIP_DET_DF)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ship_segmentator.visualize_ship_segmentation(n_images=16, is_train=False, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}