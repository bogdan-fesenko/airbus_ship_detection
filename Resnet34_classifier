{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/qubvel/classification_models.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.model_selection import train_test_split\nimport random\n\n# from tensorflow.python.keras._impl import keras\n# from tensorflow.python import keras\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.layers import InputLayer\n\n# import tensorflow as tf\n\nfrom classification_models.keras import Classifiers\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Input files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PATH = './'\nTRAIN = '../input/airbus-ship-detection/train_v2/'\nTEST = '../input/airbus-ship-detection/test_v2/'\nSEGMENTATION = '../input/airbus-ship-detection/train_ship_segmentations_v2.csv'\nexclude_list = ['6384c3e78.jpg','13703f040.jpg', '14715c06d.jpg',  '33e0ff2d5.jpg',\n                '4d4e09f2a.jpg', '877691df8.jpg', '8b909bb20.jpg', 'a8d99130e.jpg', \n                'ad55c3143.jpg', 'c8260c541.jpg', 'd6c7f17c7.jpg', 'dc3e7c901.jpg',\n                'e44dffe88.jpg', 'ef87bad36.jpg', 'f083256d8.jpg'] #corrupted image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seg_df = pd.read_csv(SEGMENTATION)\nprint(\"Original DF shape:\", seg_df.shape)\n\nseg_df['label'] = 'Ship'\nseg_df.loc[seg_df['EncodedPixels'].isna(), 'label'] = 'No_ship'\ndel seg_df['EncodedPixels']\nseg_df.columns = ['image_name', 'label']\n#drop duplicates because we have multiple masks for image with multiple ships\nseg_df = seg_df.drop_duplicates('image_name')\n\nprint(seg_df.shape)\nseg_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_names = [f for f in os.listdir(TRAIN)]\n# SAMPLE TRAIN DATA\nrandom.shuffle(train_names)\n# train_names = train_names[:20000]  # train_names[:7000] #\n\ntest_names = [f for f in os.listdir(TEST)]\nfor el in exclude_list:\n    if(el in train_names): train_names.remove(el)\n    if(el in test_names): test_names.remove(el)\n#5% of data in the validation set is sufficient for model evaluation\nX_train_images, X_val_images = train_test_split(train_names, test_size=0.05, random_state=42)\n\nseg_df_train = seg_df[seg_df['image_name'].isin(X_train_images)]\nseg_df_val = seg_df[seg_df['image_name'].isin(X_val_images)]\nprint(\"seg_df_train.shape:\", seg_df_train.shape)\nprint(\"seg_df_val.shape:\", seg_df_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Balance the dataset to 40/60 ship/no_ship"},{"metadata":{"trusted":true},"cell_type":"code","source":"seg_df = seg_df_train\nship_images_cnt = seg_df[seg_df['label'] == 'Ship'].shape[0]\nexclude_non_ship_images_cnt = seg_df.shape[0]-2*ship_images_cnt\nlist_ids_exclude = seg_df[seg_df['label']!= 'Ship'].sample(exclude_non_ship_images_cnt)['image_name']\nseg_df = seg_df[~seg_df['image_name'].isin(list_ids_exclude)]\nprint(\"ship labels (few for multiple ships per image):\", seg_df[seg_df['label'] == 'Ship'].shape[0])\nprint(\"non ship labels:\", seg_df[seg_df['label'] != 'Ship'].shape[0])\nseg_df_train = seg_df\nseg_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DataLoader"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = 256\nbatch_size = 64\n\ndef create_datagenerators(input_size, train_generator=None, validation_generator=None, batch_size=64):\n\n    # this is the augmentation configuration we will use for training\n    train_datagen = ImageDataGenerator(\n            rescale=1./255,\n            rotation_range=20,\n            brightness_range=(0.95,1.05),\n            vertical_flip=True,\n            horizontal_flip=True)\n\n    # this is the augmentation configuration we will use for testing:\n    # only rescaling\n    val_datagen = ImageDataGenerator(rescale=1./255)\n\n    # this is a generator that will read pictures found in\n    # subfolers of 'data/train', and indefinitely generate\n    # batches of augmented image data\n    train_generator = train_datagen.flow_from_dataframe(dataframe=seg_df_train,\n                                                directory=TRAIN,\n                                                x_col=\"image_name\",\n                                                y_col=\"label\",\n                                                class_mode=\"binary\", # since we use binary_crossentropy loss, we need binary labels\n                                                target_size=(input_size, input_size),\n                                                batch_size=batch_size)\n\n    validation_generator = val_datagen.flow_from_dataframe(dataframe=seg_df_val,\n                                                directory=TRAIN,\n                                                x_col=\"image_name\",\n                                                y_col=\"label\",\n                                                class_mode=\"binary\", # since we use binary_crossentropy loss, we need binary labels\n                                                target_size=(input_size, input_size),\n                                                batch_size=batch_size)\n    print(\"Data generators are recreated with new size:\", input_size)\n    return train_generator, validation_generator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def change_model_input_shape(model, lr, new_input_shape=(None, 40, 40, 3)):\n    # replace input shape of first layer\n    model._layers[0].batch_input_shape = new_input_shape\n\n    # rebuild model architecture by exporting and importing via json\n    new_model = keras.models.model_from_json(model.to_json())\n\n    # copy weights from old model to new one\n    for layer in new_model.layers:\n        try:\n            layer.set_weights(model.get_layer(name=layer.name).get_weights())\n        except:\n            print(\"Could not transfer weights for layer {}\".format(layer.name))\n    \n    # train\n    del model\n    adam = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, amsgrad=False)\n    new_model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n    return new_model\n    \ndef change_input_shape(model, lr=0.0001, new_input_size=256, batch_size=64):\n    print(\"Changing model's input shape to:\", new_input_size)\n    model = change_model_input_shape(model, lr=lr, new_input_shape=(None, new_input_size, new_input_size, 3))\n    print(\"Creating datagenerators...\")\n    train_generator, validation_generator = create_datagenerators(new_input_size, batch_size=batch_size)\n    return model, train_generator, validation_generator\n# new_model = change_model(model, new_input_shape=(None, 768, 768, 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build model"},{"metadata":{"trusted":true},"cell_type":"code","source":"ResNet34, preprocess_input = Classifiers.get('resnet34')\nn_classes = 1\n\n# build model\nbase_model = ResNet34(input_shape=(input_size,input_size,3), weights='imagenet', include_top=False)\nx = base_model.output\n# x = keras.layers.GlobalAveragePooling2D()(base_model.output)\nx = keras.layers.SpatialDropout2D(0.5)(x)\nx = keras.layers.GlobalMaxPooling2D()(x)\noutput = keras.layers.Dense(n_classes, activation='sigmoid')(x)\nmodel = keras.models.Model(inputs=[base_model.input], outputs=[output])\n\n# compile the model\nadam = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\nmodel.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.load_weights('ResNet34_ship_detection_256_2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PRETRAINED_ENCODER_PATH = '../input/airbus-ship-detection-resnet34-256px'\nPRETRAINED_ENCODER_NAME = 'ResNet34_ship_detection_256_3.h5'\n\nmodel.load_weights(os.path.join(PRETRAINED_ENCODER_PATH, PRETRAINED_ENCODER_NAME))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Find right learning rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import Callback\nimport keras.backend as K\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass LRFinder(Callback):\n    def __init__(self, min_lr, max_lr, mom=0.9, stop_multiplier=None, \n                 reload_weights=True, batches_lr_update=5):\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.mom = mom\n        self.reload_weights = reload_weights\n        self.batches_lr_update = batches_lr_update\n        if stop_multiplier is None:\n            self.stop_multiplier = -20*self.mom/3 + 10 # 4 if mom=0.9\n                                                       # 10 if mom=0\n        else:\n            self.stop_multiplier = stop_multiplier\n        \n    def on_train_begin(self, logs={}):\n        p = self.params\n        try:\n            n_iterations = p['epochs']*p['samples']//p['batch_size']\n        except:\n            n_iterations = p['steps']*p['epochs']\n            \n        self.learning_rates = np.geomspace(self.min_lr, self.max_lr, \\\n                                           num=n_iterations//self.batches_lr_update+1)\n        self.losses=[]\n        self.iteration=0\n        self.best_loss=0\n        if self.reload_weights:\n            self.model.save_weights('tmp.hdf5')\n        \n    \n    def on_batch_end(self, batch, logs={}):\n        loss = logs.get('loss')\n        \n        if self.iteration!=0: # Make loss smoother using momentum\n            loss = self.losses[-1]*self.mom+loss*(1-self.mom)\n        \n        if self.iteration==0 or loss < self.best_loss: \n                self.best_loss = loss\n                \n        if self.iteration%self.batches_lr_update==0: # Evaluate each lr over 5 epochs\n            \n            if self.reload_weights:\n                self.model.load_weights('tmp.hdf5')\n          \n            lr = self.learning_rates[self.iteration//self.batches_lr_update]            \n            K.set_value(self.model.optimizer.lr, lr)\n\n            self.losses.append(loss)            \n\n        if loss > self.best_loss*self.stop_multiplier: # Stop criteria\n            self.model.stop_training = True\n                \n        self.iteration += 1\n    \n    def on_train_end(self, logs=None):\n        if self.reload_weights:\n                self.model.load_weights('tmp.hdf5')\n                \n        plt.figure(figsize=(12, 6))\n        plt.plot(self.learning_rates[:len(self.losses)], self.losses)\n        plt.xlabel(\"Learning Rate\")\n        plt.ylabel(\"Loss\")\n        plt.xscale('log')\n        plt.show()\n        \nlr_finder = LRFinder(min_lr=1e-7, max_lr=1e-4, mom=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# input_size = 256\n# batch_size = 64\n# lr = 0.0003\n# epochs = 1\n\n# model, train_generator, validation_generator = change_input_shape(model, lr=lr, new_input_size=input_size, batch_size=batch_size)\n# print(\"Start training...\")\n# model.fit_generator(generator=train_generator, \n#                     validation_data=validation_generator,\n#                     epochs=epochs,\n#                     workers=2,\n#                    callbacks=[lr_finder])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('boat_detector')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=1e-6)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=10) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = 256\nbatch_size = 64\nlr = 3*1e-7  # optimal LR  5*1e-5, when acc=97 lr=3*1e-7\nepochs = 2\ntraining_steps = min(400, len(train_names)//batch_size)\n\nmodel, train_generator, validation_generator = change_input_shape(model, lr=lr, new_input_size=input_size, batch_size=batch_size)\nprint(\"Start training...\")\nhistory_256 = model.fit_generator(generator=train_generator, \n                    validation_data=validation_generator,\n                    steps_per_epoch=training_steps,\n                    epochs=epochs,\n                    workers=2,\n                    callbacks=callbacks_list)\n\nmodel.save('ResNet34_ship_detection_256_4.h5')\n\n# Changing model's input shape to: 256\n# Creating datagenerators...\n# Found 47500 validated image filenames belonging to 2 classes.\n# Found 2500 validated image filenames belonging to 2 classes.\n# Data generators are recreated with new size: 256\n# Start training...\n# Epoch 1/3\n# 743/743 [==============================] - 1237s 2s/step - loss: 0.1511 - accuracy: 0.9448 - val_loss: 0.3524 - val_accuracy: 0.9024\n# Epoch 2/3\n# 523/743 [====================>.........] - ETA: 5:35 - loss: 0.1079 - accuracy: 0.9604\n\n# 143/704 [=====>........................] - ETA: 15:47 - loss: 0.1574 - accuracy: 0.9602 WITH MAXPOOL\n\n# BELOW WITH SPATIALDROPOUT2D(0.5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing model's input shape to: 256\n# Creating datagenerators...\n# Found 80944 validated image filenames belonging to 2 classes.\n# Found 4168 validated image filenames belonging to 2 classes.\n# Data generators are recreated with new size: 256\n# Start training...\n# Epoch 1/10\n#  58/400 [===>..........................] - ETA: 10:54 - loss: 0.2823 - accuracy: 0.9189\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('ResNet34_ship_detection_256_4.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.plot(history_256)\nhistory_256.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.save('ResNet34_ship_detection_256.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = 384\nbatch_size = 64\nlr = 0.0003 # optimal lr  0.0003\nepochs = 1\n\nmodel, train_generator, validation_generator = change_input_shape(model, lr=lr, new_input_size=input_size, batch_size=batch_size)\nprint(\"Start training...\")\nhistory_384 = model.fit_generator(generator=train_generator, \n                    validation_data=validation_generator,\n                    epochs=epochs,\n                    workers=2,\n                    callbacks=callbacks_list)\nmodel.save('ResNet34_ship_detection_384.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seg_df = pd.read_csv(SEGMENTATION)\nprint(\"Original DF shape:\", seg_df.shape)\n\nseg_df['label'] = 'Ship'\nseg_df.loc[seg_df['EncodedPixels'].isna(), 'label'] = 'No_ship'\ndel seg_df['EncodedPixels']\nseg_df.columns = ['image_name', 'label']\n#drop duplicates because we have multiple masks for image with multiple ships\nseg_df = seg_df.drop_duplicates('image_name')\n\nprint(seg_df.shape)\nseg_df.head()\n\n###########################\n\ntrain_names = [f for f in os.listdir(TRAIN)]\n# SAMPLE TRAIN DATA\nrandom.shuffle(train_names)\ntrain_names = train_names[:15000]  # train_names[:7000] #\n\ntest_names = [f for f in os.listdir(TEST)]\nfor el in exclude_list:\n    if(el in train_names): train_names.remove(el)\n    if(el in test_names): test_names.remove(el)\n#5% of data in the validation set is sufficient for model evaluation\nX_train_images, X_val_images = train_test_split(train_names, test_size=0.05, random_state=42)\n\nseg_df_train = seg_df[seg_df['image_name'].isin(X_train_images)]\nseg_df_val = seg_df[seg_df['image_name'].isin(X_val_images)]\nprint(\"seg_df_train.shape:\", seg_df_train.shape)\nprint(\"seg_df_val.shape:\", seg_df_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = 768\nbatch_size = 16\nlr = 0.0003  # optimal lr\nepochs = 2\n\nmodel, train_generator, validation_generator = change_input_shape(model, lr=lr, new_input_size=input_size, batch_size=batch_size)\nprint(\"Start training...\")\nhistory_768 = model.fit_generator(generator=train_generator, \n                    validation_data=validation_generator,\n                    epochs=epochs,\n                    workers=2)\nmodel.save('ResNet34_ship_detection_768.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfor i in range(X.shape[0]):\n    plt.imshow(X[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
